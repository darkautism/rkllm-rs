# rkllm-rs

`rkllm-rs` æ˜¯ä¸€å€‹ä½¿ç”¨ Rust FFI åŒ…è£ `librkllmrt` çš„å‡½å¼åº«ã€‚

## README.md

- en [English](README.md)
- zh_TW [ç¹é«”ä¸­æ–‡](README.zh_TW.md)

## ç³»çµ±éœ€æ±‚

åœ¨ä½¿ç”¨ `rkllm-rs` ä¹‹å‰ï¼Œéœ€è¦å…ˆå®‰è£ `librkllmrt`ã€‚è«‹å¾ä»¥ä¸‹éˆæ¥ä¸‹è¼‰ä¸¦å®‰è£ï¼š

[ä¸‹è¼‰ librkllmrt.so](https://github.com/airockchip/rknn-llm/raw/refs/heads/main/rkllm-runtime/Linux/librkllm_api/aarch64/librkllmrt.so)

è«‹å°‡ `librkllmrt.so` å®‰è£è‡³ä»¥ä¸‹çš„å¸¸è¦‹ Linux å‡½å¼åº«è·¯å¾‘ä¹‹ä¸€ï¼š

- `/usr/lib`
- `/lib`
- `/usr/local/lib`
- `/opt/lib`

æˆ–è€…æ‚¨å¯ä»¥ä½¿ç”¨ `LD_LIBRARY_PATH` ç’°å¢ƒè®Šæ•¸ä¾†æŒ‡å®šå‡½å¼åº«è·¯å¾‘ã€‚ä¾‹å¦‚ï¼š

```sh
export LD_LIBRARY_PATH=/path/to/your/library:$LD_LIBRARY_PATH

```

æœ¬ä¾‹ä½¿ç”¨çš„æ¨¡å‹[åœ¨æ­¤](https://huggingface.co/VRxiaojie/DeepSeek-R1-Distill-Qwen-7B-RK3588S-RKLLM1.1.4)

å°æ–¼è¨˜æ†¶é«”æ¯”è¼ƒå°çš„æ¿å­ï¼Œå¯ä»¥æ”¹ä½¿ç”¨[é€™å€‹](https://huggingface.co/VRxiaojie/DeepSeek-R1-Distill-Qwen-1.5B-RK3588S-RKLLM1.1.4)

## å®‰è£

### Install Rust

ä¸ç®¡æ€éº¼æ¨£å…ˆå®‰è£rustï¼Œæˆ–è€…[åƒè€ƒ](https://www.rust-lang.org/tools/install)

```
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
```

### æ‡¶

```
# If you already installed git-lfs, skip this steps
sudo apt install gitlfs


sudo curl -L https://github.com/airockchip/rknn-llm/raw/refs/heads/main/rkllm-runtime/Linux/librkllm_api/aarch64/librkllmrt.so -o /usr/lib/librkllmrt.so
cargo install rkllm-rs --features bin
git clone https://huggingface.co/VRxiaojie/DeepSeek-R1-Distill-Qwen-1.5B-RK3588S-RKLLM1.1.4
rkllm ./DeepSeek-R1-Distill-Qwen-1.5B-RK3588S-RKLLM1.1.4/deepseek-r1-1.5B-rkllm1.1.4.rkllm --model_type=deepseek
```

é€™æ¨£ä½ å°±èƒ½çœ‹åˆ°llmå•Ÿå‹•äº†

```
I rkllm: rkllm-runtime version: 1.1.4, rknpu driver version: 0.9.7, platform: RK3588

rkllm init success
Say something: Hello

Robot: 
<think>

</think>

Hello! How can I assist you today? ğŸ˜Š
Say something:
```

### ä»¥libraryä½¿ç”¨

åœ¨ä½ çš„cargo.tomlåŠ å…¥

```

[dependencies]
rkllm-rs = "0.1.0"

```

### ä»¥binaryä½¿ç”¨

rkllm-rsä¹Ÿæ”¯æŒä»¥binaryæ–¹å¼å•Ÿå‹•ï¼Œé©åˆä¸æ‰“ç®—é€²è¡ŒäºŒæ¬¡é–‹ç™¼æˆ–è€…æ‰“ç®—é–‹ç®±å³ç”¨çš„ä½¿ç”¨è€…

```
cargo install rkllm-rs --features bin
rkllm ~/DeepSeek-R1-Distill-Qwen-1.5B-RK3588S-RKLLM1.1.4/deepseek-r1-1.5B-rkllm1.1.4.rkllm --model_type=deepseek
```

é€™æ˜¯å·¥å…·çš„helpï¼Œå„ç¨®åƒæ•¸ä¾ç…§helpè¨­å®š

```
Usage: rkllm [OPTIONS] [model]

Arguments:
  [model]  Rkllm model

Options:
      --model_type <model_type>
          some module have special prefix in prompt, use this to fix [possible values: normal, deepseek]
  -c, --context_len <max_context_len>
          Maximum number of tokens in the context window
  -n, --new_tokens <max_new_tokens>
          Maximum number of new tokens to generate.
  -K, --top_k <top_k>
          Top-K sampling parameter for token generation.
  -P, --top_p <top_p>
          Top-P (nucleus) sampling parameter.
  -t, --temperature <temperature>
          Sampling temperature, affecting the randomness of token selection.
  -r, --repeat_penalty <repeat_penalty>
          Penalty for repeating tokens in generation.
  -f, --frequency_penalty <frequency_penalty>
          Penalizes frequent tokens during generation.
  -p, --presence_penalty <presence_penalty>
          Penalizes tokens based on their presence in the input.
      --prompt_cache <prompt_cache_path>
          Path to the prompt cache file.
      --skip_special_token
          Whether to skip special tokens during generation.
  -h, --help
          Print help (see more with '--help')
  -V, --version
          Print version
```

## Online Tokenizer Config

ç›®å‰æœ¬åœ°çš„æ¨¡å‹é¡åˆ¥éƒ½æ˜¯ç”±hardcodeåœ¨ç¨‹å¼ç¢¼å…§çš„ï¼Œæ²’æœ‰æ”¯æ´çš„æ¨¡å‹ï¼Œä¸¦ä¸æœƒæ­£ç¢ºçš„ç”Ÿæˆbos_tokenå’Œassistantæç¤ºè©ã€‚å¤§å¤šæ•¸æ¨¡å‹åœ¨æ²’æœ‰é‡åˆ°æ­£ç¢ºæç¤ºè©æ™‚æœƒç™¼ç”ŸéŒ¯äº‚ï¼Œä¾‹å¦‚ç­”éæ‰€å•ï¼Œè‡ªå•è‡ªç­”(å¥½å§ï¼Œå…¶å¯¦æä¾›äº†ä»–é‚„æ˜¯åœ¨è‡ªå•è‡ªç­”)ã€‚

ç›®å‰å¤§å¤šæ•¸çš„æ¨¡å‹çš†åœ¨ç·šä¸Šæ”¾ç½®äº†tokenizer_config.jsonï¼Œè®€å–è©²é…ç½®å¯ä»¥ç”Ÿæˆæ­£ç¢ºçš„æç¤ºè©

ä½ å¯ä»¥è‡ªå·±é€šéæ‹¼æ¹Štokenizer_config.jsonä¾†ç”Ÿæˆæç¤ºè©ï¼Œæˆ–è€…ä½¿ç”¨pythonçš„AutoTokenizerç”Ÿæˆã€‚

ç›®å‰è©²åº«æä¾›äº†ä¸€ç¨®æ–¹æ³•å¯ä»¥è‡ªå‹•å¾ç·šä¸ŠæŠ“å–å°æ‡‰æ¨¡å‹çš„tokenizer_config.json

```
cargo install rkllm-rs  --features "bin, online_config"
rkllm ~/Tinnyllama-1.1B-rk3588-rkllm-1.1.4/TinyLlama-1.1B-Chat-v1.0-rk3588-w8a8-opt-0-hybrid-ratio-0.5.rkllm --model_type=TinyLlama/TinyLlama-1.1B-Chat-v1.0
```

é€™æ¨£å·¥å…·å°±æœƒå¾ç·šä¸ŠæŠ“å–TinyLlamaçš„tokenizer_config.jsonï¼Œä¸¦å˜—è©¦ä¿®æ­£prompt